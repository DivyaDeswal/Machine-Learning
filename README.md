# ğŸ¤– Machine Learning Algorithms
Welcome to my Machine Learning Algorithms repository! ğŸš€ This repo contains Jupyter notebooks implementing Supervised and Unsupervised Machine Learning algorithms with explanations and code examples.

## ğŸ“‚ Algorithms Included
### 1ï¸âƒ£ Linear Regression
ğŸ“Œ Type: Supervised Learning (Regression)

ğŸ“Œ Use Case: Predicting continuous values (e.g., house prices, sales forecasting).

ğŸ”§ Libraries Used: sklearn, pandas, numpy, matplotlib.

### 2ï¸âƒ£ Logistic Regression
ğŸ“Œ Type: Supervised Learning (Classification)

ğŸ“Œ Use Case: Binary classification problems (e.g., spam detection, disease prediction).

ğŸ”§ Libraries Used: sklearn, numpy, matplotlib.

### 3ï¸âƒ£ Decision Tree Algorithm
ğŸ“Œ Type: Supervised Learning (Classification & Regression)

ğŸ“Œ Use Case: Customer segmentation, credit risk assessment.

ğŸ“Œ How it Works:

The model splits data into branches based on feature conditions.
Uses Gini Index or Entropy to determine splits.

Forms a tree structure where leaves represent outcomes.

ğŸ”§ Libraries Used: sklearn.tree, pandas, matplotlib.

### 4ï¸âƒ£ Random Forest Algorithm (Iris Dataset)
ğŸ“Œ Type: Supervised Learning (Classification)

ğŸ“Œ Use Case: Complex classification problems (e.g., medical diagnosis, image recognition).

ğŸ“Œ How it Works:

An ensemble method combining multiple decision trees.
Each tree votes, and the most common prediction is selected (majority voting).
Reduces overfitting compared to a single decision tree.

ğŸ”§ Libraries Used: sklearn.ensemble.RandomForestClassifier, pandas, matplotlib.

### 5ï¸âƒ£ K-Means & Hierarchical Clustering
ğŸ“Œ Type: Unsupervised Learning (Clustering)

ğŸ“Œ Use Case: Customer segmentation, anomaly detection.

ğŸ“Œ How it Works:

K-Means Clustering
Defines K clusters (centroids).
Assigns each data point to the nearest cluster center.
Updates centroids until convergence.

#### Hierarchical Clustering
Creates a hierarchy of clusters using Agglomerative (bottom-up) or Divisive (top-down) methods.
Uses Dendrograms to visualize cluster merging.

ğŸ”§ Libraries Used: sklearn.cluster, scipy.cluster.hierarchy, matplotlib, seaborn.

#### ğŸ› ï¸ Tools & Libraries Used
Python ğŸ

Jupyter Notebook

Scikit-Learn (sklearn)

Pandas, NumPy, Matplotlib, Seaborn

#### ğŸ“Œ How to Use
Clone the repository:
git clone https://github.com/DivyaDeswal/Machine-Learning.git

Open the notebooks in Jupyter or Google Colab.
Run the code and experiment with different models

## ğŸ“‚ Classifiers
### Boosting Ensemble Techniques

Boosting is a powerful ensemble technique that combines multiple weak classifiers to form a strong classifier. The following methods are implemented in this repository:

### 1ï¸âƒ£ Adaboost (Adaptive Boosting): 
A technique that adjusts weights iteratively to emphasize misclassified instances.

### 2ï¸âƒ£ XGBoost (Extreme Gradient Boosting): 
An optimized gradient boosting library designed for speed and performance.

### 3ï¸âƒ£ LightGBM (Light Gradient Boosting Machine): 
A gradient boosting framework that uses tree-based learning algorithms for faster training on large datasets.

## Dimensionality Reduction Techniques

### ğŸ“Œ Objective

Dimensionality reduction helps reduce the number of input variables in a dataset while retaining as much meaningful information as possible. This technique is particularly useful for handling high-dimensional data.

### ğŸ› ï¸ Techniques Used

## Principal Component Analysis (PCA):

Transforms high-dimensional data into a lower-dimensional space while retaining the most significant features.

Applied PCA to the liver patient dataset to aid in feature selection and model efficiency.

### ğŸ” Implementation

## 1ï¸âƒ£ Customer Segmentation for Retail

Objective: Segment customers based on purchasing behavior.

Techniques Used: Clustering algorithms such as K-Means and Hierarchical Clustering.

Use Case: Helps businesses identify customer groups and tailor marketing strategies accordingly.

Implementation:

Dataset consists of customer purchase history.

Clustering techniques applied to identify different customer segments.

Enhances customer engagement and improves business strategies.

## 2ï¸âƒ£ Zomato Restaurant Price Prediction (Accuracy: 0.92)

Objective: Predict restaurant prices based on various factors such as location, cuisine, ratings, and reviews.

Techniques Used: Regression models including Linear Regression, Decision Trees, and Random Forest.

Use Case: Assists customers in understanding pricing trends and helps restaurant owners optimize pricing strategies.

Implementation:

Dataset includes restaurant details like type of cuisine, location, ratings, and price range.

Regression models trained to predict restaurant price range with high accuracy (0.92).

Enables better decision-making for both consumers and business owners.

